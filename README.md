# Taking images of food is quickly replacing written food diaries as the primary means of food logging for people who want to monitor their food choices. Automatically analyzing the content of these food images can provide users and health experts with invaluable information about a user's eating and possibly help plan diet charts, diagnose diet-related medical conditions, or plan treatments for existing conditions. There are several challenges with image-based food recognition â€“ estimating the volume of food, recognizing occluded ingredients, etc. Food images from these logs often contain a mix of packaged and unpackaged food, which have fundamentally different structures. It adds further complexity to an already difficult recognition task. One way to simplify this problem is to classify images into two categories (packaged and unpackaged) during the preprocessing step and then feed these sets of images into separate models for further processing. In this Project, we tackle the problem of segregating packaged and unpackaged food images.
